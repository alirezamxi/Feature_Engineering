{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CSCE 5222 Feature Engineering — Gabor Filter Bank on SOCOFing\n",
        "\n",
        "Group 7  \n",
        "Members: Amir Naderian, Alireza Mohammadshafie\n",
        "\n",
        "---\n",
        "\n",
        "This notebook reproduces the complete pipeline for fingerprint alteration detection using Gabor features, as requested.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset root: /Users/alireza.mohammadshafie/Documents/Projects/Feature_engineering/Project/notebooks/SOCOFing\n"
          ]
        }
      ],
      "source": [
        "# Setup & Config\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from skimage import io, color, transform\n",
        "from skimage.filters import gabor\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Reproducibility\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)\n",
        "\n",
        "# Paths\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "# Search upward for the SOCOFing folder in case notebook is inside notebooks/\n",
        "possible_root = PROJECT_ROOT\n",
        "while possible_root != possible_root.parent and not (possible_root / 'SOCOFing').exists():\n",
        "    possible_root = possible_root.parent\n",
        "DATASET_ROOT = possible_root / 'SOCOFing'\n",
        "print('Resolved dataset root:', DATASET_ROOT)\n",
        "print('Dataset root:', DATASET_ROOT)\n",
        "\n",
        "# Parameters\n",
        "IMG_SIZE = (128, 128)\n",
        "THETAS_DEG = [0, 45, 90, 135, 180]\n",
        "FREQS = [0.1, 0.2, 0.3]\n",
        "TEST_SIZE = 0.2\n",
        "CV_FOLDS = 5\n",
        "N_JOBS = -1\n",
        "\n",
        "# Optional subsampling (None for full dataset)\n",
        "MAX_PER_CLASS = None  # e.g., 100\n",
        "\n",
        "sns.set_theme(style='whitegrid', context='notebook')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "SOCOFing Real/Altered folders not found at expected location",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m altered_dir = DATASET_ROOT / \u001b[33m'\u001b[39m\u001b[33mAltered\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m real_dir.exists() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m altered_dir.exists():\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mSOCOFing Real/Altered folders not found at expected location\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_images\u001b[39m(dir_path: Path) -> List[Path]:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m dir_path.rglob(\u001b[33m'\u001b[39m\u001b[33m*\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m p.suffix.lower() \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_EXTS]\n",
            "\u001b[31mFileNotFoundError\u001b[39m: SOCOFing Real/Altered folders not found at expected location"
          ]
        }
      ],
      "source": [
        "# Dataset loading & labeling\n",
        "from typing import List\n",
        "\n",
        "SUPPORTED_EXTS = {'.bmp', '.png', '.jpg', '.jpeg', '.tif', '.tiff'}\n",
        "real_dir = DATASET_ROOT / 'Real'\n",
        "altered_dir = DATASET_ROOT / 'Altered'\n",
        "\n",
        "if not real_dir.exists() or not altered_dir.exists():\n",
        "    raise FileNotFoundError('SOCOFing Real/Altered folders not found at expected location')\n",
        "\n",
        "\n",
        "def find_images(dir_path: Path) -> List[Path]:\n",
        "    return [p for p in dir_path.rglob('*') if p.suffix.lower() in SUPPORTED_EXTS]\n",
        "\n",
        "real_files = sorted(find_images(real_dir))\n",
        "altered_files = sorted(find_images(altered_dir))\n",
        "\n",
        "if MAX_PER_CLASS:\n",
        "    real_files = real_files[:MAX_PER_CLASS]\n",
        "    altered_files = altered_files[:MAX_PER_CLASS]\n",
        "\n",
        "print(f'Found {len(real_files)} real and {len(altered_files)} altered images')\n",
        "\n",
        "import pandas as pd\n",
        "rows = [{'path': p, 'label': 0, 'label_str': 'Real'} for p in real_files] + \\\n",
        "       [{'path': p, 'label': 1, 'label_str': 'Altered'} for p in altered_files]\n",
        "\n",
        "df = pd.DataFrame(rows).sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing helpers and sample visualisation\n",
        "from math import ceil\n",
        "\n",
        "def load_gray_and_resized(path: Path, size=IMG_SIZE):\n",
        "    img = io.imread(path.as_posix())\n",
        "    if img.ndim == 3:\n",
        "        if img.shape[2] == 4:\n",
        "            img = color.rgba2rgb(img)\n",
        "            img_gray = color.rgb2gray(img)\n",
        "        else:\n",
        "            img_gray = color.rgb2gray(img)\n",
        "    else:\n",
        "        img_gray = img.astype(np.float32)\n",
        "    img_resized = transform.resize(img_gray, size, anti_aliasing=True, mode='reflect', preserve_range=True)\n",
        "    return img_resized\n",
        "\n",
        "# Visualise a few samples\n",
        "classes = ['Real', 'Altered']\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12,6))\n",
        "for i, cls in enumerate(classes):\n",
        "    subset = df[df['label_str']==cls].sample(n=4, random_state=RANDOM_STATE)\n",
        "    for j, (_, row) in enumerate(subset.iterrows()):\n",
        "        axes[i, j].imshow(load_gray_and_resized(row.path), cmap='gray')\n",
        "        axes[i, j].axis('off')\n",
        "        if i==0:\n",
        "            axes[i, j].set_title(cls)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gabor feature utilities\n",
        "def compute_gabor_features(image_gray: np.ndarray, thetas_deg, freqs):\n",
        "    feats = []\n",
        "    for theta_deg in thetas_deg:\n",
        "        theta = np.deg2rad(theta_deg)\n",
        "        for freq in freqs:\n",
        "            real, imag = gabor(image_gray, frequency=freq, theta=theta)\n",
        "            mag = np.sqrt(real**2 + imag**2)\n",
        "            feats.extend([mag.mean(), mag.std()])\n",
        "    return np.array(feats, dtype=np.float32)\n",
        "\n",
        "def path_to_feature(path: Path):\n",
        "    img = load_gray_and_resized(path)\n",
        "    img = np.clip(img.astype(np.float32), 0, 1)\n",
        "    return compute_gabor_features(img, THETAS_DEG, FREQS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature extraction (may take a while!)\n",
        "num_features = 2*len(THETAS_DEG)*len(FREQS)\n",
        "print('Each image ->', num_features, 'features')\n",
        "\n",
        "X = np.empty((len(df), num_features), dtype=np.float32)\n",
        "for i, row in enumerate(df.itertuples(index=False)):\n",
        "    X[i] = path_to_feature(row.path)\n",
        "    if (i+1)%500==0:\n",
        "        print(f'Processed {i+1}/{len(df)}')\n",
        "\n",
        "y = df['label'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split & scaling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE)\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "print('Train size:', X_train.shape[0], 'Test size:', X_test.shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model training — k-NN and SVM\n",
        "knn_params = {'n_neighbors':[3,5,7,9]}\n",
        "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=CV_FOLDS, n_jobs=N_JOBS, scoring='accuracy')\n",
        "knn_grid.fit(X_train_s, y_train)\n",
        "print('Best k-NN:', knn_grid.best_params_)\n",
        "\n",
        "svm_params = {'C':[1,10,100], 'gamma':['scale','auto',0.01,0.001]}\n",
        "svm_grid = GridSearchCV(SVC(kernel='rbf'), svm_params, cv=CV_FOLDS, n_jobs=N_JOBS, scoring='accuracy')\n",
        "svm_grid.fit(X_train_s, y_train)\n",
        "print('Best SVM:', svm_grid.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation & results\n",
        "results = []\n",
        "\n",
        "def evaluate(name, model):\n",
        "    preds = model.predict(X_test_s)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    prec = precision_score(y_test, preds)\n",
        "    rec = recall_score(y_test, preds)\n",
        "    f1 = f1_score(y_test, preds)\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "    print(f\"\\n{name} confusion matrix:\\n\", cm)\n",
        "    results.append({'Model':name,'Accuracy':acc,'Precision':prec,'Recall':rec,'F1':f1})\n",
        "\n",
        "evaluate('k-NN', knn_grid.best_estimator_)\n",
        "evaluate('SVM', svm_grid.best_estimator_)\n",
        "\n",
        "pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discussion\n",
        "\n",
        "The table above compares k-NN and SVM on Gabor-based texture features. SVM typically excels thanks to the RBF kernel capturing non-linear boundaries, whereas k-NN offers a simpler baseline. Future work could expand the filter bank, balance classes, or explore deep learning approaches.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ACM1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
